structural_analysis_task:
  description: >
    IMPORTANT: You MUST actually CALL the Structure Extractor tool with folder_path="{folder_path}" to analyze the codebase.
    Do NOT just describe the tool - you must execute it and use its results.
    Analyze the codebase at {folder_path} and extract all structural information by calling the Structure Extractor tool.
    The tool will return files, modules, classes, and functions information.
    Create a comprehensive structural map based on the ACTUAL tool output.
  expected_output: >
    A detailed structural analysis report based on ACTUAL tool execution results, including:
    - All detected languages with file counts and percentages
    - Complete file inventory
    - Module/class/function counts
    - Entry points identified
    - Structural statistics
    Use the actual data returned by the Structure Extractor tool, not placeholder data.
  agent: structural_scanner

dependency_analysis_task:
  description: >
    IMPORTANT: You MUST actually CALL the Dependency Analyzer tool with folder_path="{folder_path}" to analyze dependencies.
    Do NOT just describe the tool - you must execute it and use its results.
    Analyze dependencies in the codebase at {folder_path} by calling the Dependency Analyzer tool.
    The tool will return import relationships, external vs internal dependencies, and dependency graph structure.
    Use the ACTUAL tool output to create your report.
  expected_output: >
    A dependency analysis report based on ACTUAL tool execution results with:
    - List of external dependencies (from tool output)
    - Internal dependency relationships (from tool output)
    - Dependency graph summary (from tool output)
    - Architectural layer identification
  agent: dependency_analyzer_agent

semantic_understanding_task:
  description: >
    Analyze the semantic meaning of the codebase structure extracted in previous tasks.
    For each major component (class, function, module):
    - Infer purpose from names, docstrings, and context
    - Assign confidence scores to inferences
    - Group related components
    - Identify patterns and conventions
    Flag any low-confidence inferences for review.
  expected_output: >
    A semantic analysis report with:
    - Component purpose descriptions with confidence scores
    - Grouped components by functionality
    - Identified patterns and conventions
    - List of low-confidence items requiring review
  agent: api_semantics_agent

architecture_analysis_task:
  description: >
    Analyze the architectural patterns and design of the codebase.
    Based on structure and semantic understanding:
    - Identify architectural patterns (MVC, layered, microservices, etc.)
    - Map component roles (service, controller, model, utility, etc.)
    - Identify architectural layers
    - Explain system organization
  expected_output: >
    An architecture analysis report with:
    - Identified architectural patterns
    - Component role mapping
    - Layer structure
    - System organization explanation
  agent: architecture_agent

api_documentation_task:
  description: >
    IMPORTANT: Use the ACTUAL structural analysis results from previous tasks. Call Structure Extractor tool if needed with folder_path="{folder_path}".
    Generate comprehensive API reference documentation in JSON format based on REAL code structure.
    Extract information from the structural analysis task output - use actual classes, functions, and methods found.
    - Document all public APIs (classes, functions, methods) that ACTUALLY exist in the codebase
    - Include parameters, return types, and descriptions from actual code
    - Add usage notes and important details
    - Organize by module/namespace
    CRITICAL: Only document what actually exists - never invent APIs. Use real data from tool outputs.
    Output format: JSON array with structure:
    [
      {
        "module": "actual_module_path_from_codebase",
        "description": "Module description based on actual code",
        "classes": [
          {
            "name": "ActualClassName",
            "description": "Class description from code",
            "constructor_params": [{"name": "param", "type": "type", "description": "desc"}],
            "methods": [
              {
                "name": "actual_method_name",
                "description": "Method description from code",
                "parameters": [{"name": "param", "type": "type", "description": "desc", "required": true}],
                "returns": {"type": "return_type", "description": "description"},
                "raises": [{"exception": "ExceptionName", "description": "when raised"}],
                "example": "actual code example"
              }
            ]
          }
        ],
        "functions": [{"name": "function_name", "description": "...", "parameters": [...], "returns": {...}}]
      }
    ]
  expected_output: >
    Complete API reference in JSON format array, organized by module.
    MUST use actual data from codebase analysis - no placeholder or invented APIs.
    Each API entry must include full signature, parameters, return types, and examples based on real code.
  agent: api_doc_agent

architecture_documentation_task:
  description: >
    Create architecture overview documentation in JSON format based on ACTUAL code analysis.
    Analyze the codebase structure and extract real components, patterns, and data flow.
    
    Output format: JSON object with structure:
    {
      "summary": "2-3 sentence description of what the system does",
      "components": [
        {
          "name": "ComponentName",
          "description": "What this component does",
          "responsibilities": ["responsibility1", "responsibility2"],
          "dependencies": ["dependency1", "dependency2"]
        }
      ],
      "design_patterns": [
        {
          "pattern_name": "PatternName",
          "where_used": "Where it's used in the code",
          "rationale": "Why this pattern was chosen"
        }
      ],
      "data_flow": "How data moves through the system"
    }
    
    Use ACTUAL data from the codebase - identify real classes, functions, and their relationships.
  expected_output: >
    Architecture documentation in JSON format with summary, components, design patterns, and data flow.
    Must contain real component names and descriptions from the actual codebase.
  agent: architecture_doc_agent

example_generation_task:
  description: >
    Generate practical usage examples for the documented APIs in JSON format.
    Create examples that:
    - Are based on ACTUAL API structure from the codebase
    - Demonstrate real-world usage patterns
    - Are complete and runnable code
    - Cover common use cases (basic usage, intermediate, advanced)
    
    Output format: JSON array with structure:
    [
      {
        "title": "Descriptive Title",
        "description": "What this example demonstrates",
        "difficulty": "beginner | intermediate | advanced",
        "code": "Complete runnable code with imports and usage",
        "expected_output": "What the code produces when run",
        "setup_instructions": "Installation or setup needed"
      }
    ]
    
    Use REAL APIs from the codebase - never invent or hallucinate.
  expected_output: >
    Code examples in JSON format array with real, runnable examples based on actual APIs.
    Each example must include title, description, difficulty, code, expected_output, and setup_instructions.
  agent: example_generator_agent

getting_started_task:
  description: >
    Create a comprehensive getting started guide in JSON format based on ACTUAL project structure.
    Analyze the codebase to determine:
    - What prerequisites are needed (Python version, dependencies)
    - How to install the project
    - A quick start code example
    - Next steps for users
    
    Output format: JSON object with structure:
    {
      "prerequisites": ["Python 3.10+", "UV package manager"],
      "installation": "Installation command or instructions",
      "quick_start": "Complete runnable code example showing basic usage",
      "next_steps": ["step1", "step2", "step3"]
    }
    
    Use REAL project data - check pyproject.toml for dependencies, main.py for usage patterns.
  expected_output: >
    Getting Started guide in JSON format with real prerequisites, installation, quick_start, and next_steps.
    Based on actual project configuration and structure.
  agent: getting_started_agent

evaluation_task:
  description: >
    Evaluate the quality of all generated documentation and generate metadata.
    Count and measure:
    - Total files analyzed in the codebase
    - Total functions documented across all modules
    - Total classes documented across all modules
    - Total examples generated
    - QA issues found (coverage gaps, missing documentation, etc.)
    
    Output format: JSON object with structure:
    {
      "files_analyzed": 10,
      "total_functions_documented": 25,
      "total_classes_documented": 12,
      "examples_generated": 5,
      "qa_issues_found": [
        {
          "severity": "info | warning | error",
          "description": "Description of the issue found",
          "location": "File or component where issue was found"
        }
      ],
      "generation_timestamp": "2026-02-09T12:30:00Z"
    }
    
    Use ACTUAL counts from the codebase analysis - count real files, classes, functions.
  expected_output: >
    Quality and metadata report in JSON format with real counts, issues, and timestamp.
    Numbers must reflect actual codebase analysis.
  agent: evaluation_agent

final_documentation_assembly_task:
  description: >
    CRITICAL: You must CREATE the final documentation JSON by combining data from ALL previous tasks.
    Use the tool outputs and context from:
    - language_detection_task: Language statistics
    - structural_analysis_task: Code structure (files, classes, functions)
    - dependency_analysis_task: Dependencies
    - api_documentation_task: API reference data
    - architecture_documentation_task: Architecture overview
    - example_generation_task: Usage examples
    - getting_started_task: Getting started guide
    - evaluation_task: Quality metrics
    
    CREATE this exact JSON structure with REAL VALUES from the codebase:
    
    {
      "documentation": {
        "table_of_contents": "# Project Documentation\n\n1. [Architecture Overview](#architecture-overview)\n2. [API Reference](#api-reference)\n3. [Usage Examples](#usage-examples)\n4. [Getting Started](#getting-started)",
        "architecture_overview": {
          "summary": "A 2-3 sentence description of what this project does based on code analysis",
          "components": [
            {"name": "ComponentName", "description": "What this component does", "responsibilities": ["responsibility1"], "dependencies": []}
          ],
          "design_patterns": [
            {"pattern_name": "PatternName", "where_used": "Where it's used", "rationale": "Why it was chosen"}
          ],
          "data_flow": "How data moves through the system"
        },
        "api_reference": [
          {
            "module": "src/module_name",
            "description": "Module description from code",
            "classes": [{"name": "ClassName", "description": "Class description", "constructor_params": [], "methods": []}],
            "functions": [],
            "api_endpoints": []
          }
        ],
        "examples": [
          {"title": "Example Title", "description": "What this demonstrates", "difficulty": "beginner", "code": "code here", "expected_output": "output", "setup_instructions": "setup"}
        ],
        "getting_started": {
          "prerequisites": ["requirement1", "requirement2"],
          "installation": "install command",
          "quick_start": "code example",
          "next_steps": ["step1", "step2"]
        }
      },
      "metadata": {
        "files_analyzed": 10,
        "total_functions_documented": 25,
        "total_classes_documented": 12,
        "total_methods_documented": 50,
        "api_endpoints_found": 5,
        "examples_generated": 3,
        "qa_issues_found": [],
        "generation_timestamp": "2026-02-09T13:06:00Z"
      }
    }
    
    COUNT actual files, classes, functions, methods, API endpoints from the codebase.
    Use REAL data - no placeholder text.
  expected_output: >
    Complete technical documentation in VALID JSON format matching the specified structure exactly.
    Must contain real counts, real component names, real API endpoints - NO placeholder text.
    Output only valid JSON, nothing else.
  agent: api_doc_agent
